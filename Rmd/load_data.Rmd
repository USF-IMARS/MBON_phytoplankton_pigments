---
title: "Load Data"
author: "Sebastian DiGeronimo"
date: '2022-06-13'
output: html_document
---

# Small lists of things to do
* rename headers to be `tidy`
    can use: .name_repair = janitor::make_clean_names inside read_csv
    
* combine date and time columns to a standard date_time
    - Something like this
     mutate(
    date_time_utc = ymd_hms(paste(`year col`, `month col`, `day col`, `time col`), tz = "utc"),
    .before = lat
  )
  
* set -8888 to 0
* address notes from file to potentially ignore certain rows 
* start plotting
    * histogram, per stations, per pigments, etc
    * simple plots over time
    * maybe some heatmap
    * maybe map

```{r setup, include=FALSE}
root <- rprojroot::find_rstudio_root_file()
knitr::opts_chunk$set(echo = TRUE)
library("ggplot2")
library("tibble")
library("tidyr")
library("readr")
library("purrr")
library("dplyr")
library("stringr")
library("forcats")
library("lubridate")
library("glue")
library("fs")
library("magrittr")
```

```{r create-dir}
# will create a set directory if does not exists
# useful for new projects
mainDir <- rprojroot::find_rstudio_root_file()
subDir <-
    c("data/raw",
      "data/processed",
      "data/plots",
      "data/metadata",
      "Rmd",
      "scripts")

fs::dir_create(path = paste0(mainDir,"/",subDir))
rm(mainDir, subDir)
```


```{r file-paths}
# find carbonate data
dir <- "//data//raw//"

# pigment files
file.pig <-
  fs::dir_ls(path = paste0(root,dir),
             recurse = TRUE,
             regexp = "\\.xlsx$")

```

```{r}
df <-
    readxl::read_xlsx(
        file.pig[1],
        sheet = 2,
        skip = 8,
        na = "-9999",
        .name_repair = janitor::make_clean_names
    ) %>%
    rename(lon = longitude,
         lat = latitude) %>%
    mutate(
        gmt_time = hms::as_hms(strftime(gmt_time, format = "%H:%M:%S")),
        date_time_utc = ymd_hms(
            paste(
                year_of_sample,
                gregorian_month,
                day_of_gregorian_month,
                gmt_time
            ),
            tz = "utc"
        ),
        .before = lon, 
        date_extracted_month_day_year = as.character(date_extracted_month_day_year)
        #converted to character so that I could join df and df5
    )

# set -8888 to 0, represent below Limit of Detection (LOD)
df[df == -8888] <- 0
```

```{r}
df2 <- 
    readxl::read_xlsx(file.pig[2], sheet = 2, skip = 8, na = "-9999", 
                      .name_repair = janitor::make_clean_names) %>%
    mutate(
        time = hms::as_hms(strftime(time, format = "%H:%M:%S")),
        date_time_utc = ymd_hms(
            paste(
                year, month, day, time
            ),
            tz = "utc"
        ),
        .before = lon
    ) %>%
    mutate(indicate_if_filters_are_replicates = as.character(indicate_if_filters_are_replicates)) %>%
    rename(filter_storage_before_shipment_to_gsfc = filter_storage_before_shipment_to_gfc) %>%
    filter(!is.na(station))
df2[df2 == -8888] <- 0



df3 <-
    readxl::read_xlsx(
        file.pig[3],
        sheet = "Report",
        skip = 8,
        na = "-9999",
        .name_repair = janitor::make_clean_names
    ) %>%
    mutate(
        time = hms::as_hms(strftime(time, format = "%H:%M:%S")),
        date_time_utc = ymd_hms(paste(year, month, day, time),
                                tz = "utc"),
        .before = lon
    ) %>%
    mutate(indicate_if_filters_are_replicates = as.character(indicate_if_filters_are_replicates),
           # matches any digit or decimal and convert to numeric
           water_depth = as.numeric(str_extract(water_depth, "\\d*\\.{0,1}\\d")),
           water_depth = replace_na(water_depth, 0)
    )
df3[df3 == -8888] <- 0

df4 <-
    readxl::read_xlsx(
        file.pig[4],
        sheet = "Report",
        skip = 8,
        na = "-9999",
        .name_repair = janitor::make_clean_names
    )  %>%
    # Fixed misspelled month
    mutate(month = case_when(!month %in% c(month.name, month.abb) ~ str_extract(month, "\\w{3}"),
           TRUE ~ month)) %>%
    mutate(
        time = hms::as_hms(strftime(time, format = "%H:%M:%S")),
        date_time_utc = ymd_hms(paste(year, month, day, time),
                                tz = "utc"),
        .before = lon
    ) %>%
    mutate(depth = as.numeric(str_extract(depth, "\\d*\\.{0,1}\\d")))
df4[df4 == -8888] <- 0

df234 <- 
    full_join(df3, df2) 
df234 <- mutate(df234, hplc_gsfc_id = case_when(is.na(hplc_gsfc_id) ~ gsfc_sample_code,
                                           TRUE ~ hplc_gsfc_id))
df234 <- full_join(df234, df4) %>%
    mutate(sequential_sample_number = as.numeric(sequential_sample_number)) #one cell had "28A", converted to NA
```
```{r}
df5 <-
    readxl::read_xlsx(
        file.pig[5],
        sheet = "Report",
        skip = 8,
        na = "-9999",
        .name_repair = janitor::make_clean_names
    ) %>%
    rename(lon = longitude,
         lat = latitude) %>%
    mutate(
        gmt_time = hms::as_hms(strftime(gmt_time, format = "%H:%M:%S")),
        date_time_utc = ymd_hms(
            paste(
                year_of_sample,
                gregorian_month,
                day_of_gregorian_month,
                gmt_time
            ),
            tz = "utc"
        ),
        .before = lon,
        date_extracted_month_day_year = na_if(date_extracted_month_day_year, "box")
    )

# set -8888 to 0, represent below Limit of Detection (LOD)
df5[df5 == -8888] <- 0

df15 <- full_join(df, df5)

params <- c("hplc_gsfc_id"="gsfc_lab_sample_code", "pi", "station", "sample" = "original_pi_sample_label", 
            "cruise"="cruise_name", "indicate_if_filters_are_replicates",
            "volfilt" = "volume_filtered_ml", "bottle" ="bottle_number", 
            "depth" = "sampling_depth_meters", "water_depth" = "total_water_depth_meters",
            "name_of_water_body", "year" = "year_of_sample", "month"= "gregorian_month",
            "day" = "day_of_gregorian_month", "sdy" = "sequential_day_of_year", 
            "time"="gmt_time", "date_time_utc","lon", "lat", "filter_type",
            "filter_diameter_mm", "filter_storage_before_shipment_to_gfsc"="filter_storage_before_shipping_to_gsfc",
            "tot_chl_a", "tot_chl_b", "tot_chl_c", "alpha_beta_car","but_fuco", 
            "hex_fuco", "allo", "diadino", "diato", "fuco", "perid", "zea", "mv_chl_a", 
            "dv_chl_a", "chlide_a", "mv_chl_b", "dv_chl_b", "chl_c1c2" = "chl_c12",
            "chl_c3", "lut", "neo", "viola", "phytin_a", "phide_a", "pras", "gyro", 
            "tchl"="t_chl", "ppc", "psc", "psp", "tcar"="t_caro", "tacc" = "t_acc",
            "tpg" = "t_pg", "dp", "tacc_tchla" = "t_acc_tchla", "psc_tcar" = "psc_t_caro",
            "ppc_tcar" = "ppc_t_caro", "tchl_tcar"="t_chl_t_caro", "ppc_tpg" = "ppc_tpig",
            "psp_tpg" = "psp_t_pg", "tchl_a_tpg" = "t_chl_a_t_pig",
            "comments", "sequential_sample_number")

dfall <- full_join(df234, df15, by=params)
dfall <- mutate(dfall, lat = case_when(lat < 0 ~ lat*(-1),
                                TRUE ~ lat),
                lon = case_when(lon > 0 ~ lon*(-1),
                                TRUE ~ lon)
)


#for looking at similarities in the column names between different files
# x <- cbind(names(df),names(df2),names(df3),names(df4),names(df5))
# x2 <- cbind(names(df234), names(df15))
```

```{r summary statistics}
#group by seasons
dfall$month <- strtrim(dfall$month, 3)
winter <- c("Dec", "Jan", "Feb")
spring <- c("Mar","Apr", "May")
summer <- c("Jun","Jul", "Aug")
autumn <- c("Sep","Nov", "Oct")

dfall <- mutate(dfall, season = case_when(month %in% winter ~ "W",
                                          month %in% spring ~ "Sp",
                                          month %in% summer ~ "Su",
                                          month %in% autumn ~ "F"))
pig_stat <- dfall %>%
    group_by(season) %>% 
    summarise_at(vars(tot_chl_a:tchl_a_tpg),list(avg = mean, sd= sd, var= var), na.rm = TRUE)

```

```{r}

dir2 <- "//data//processed//"
path_out = paste0(root,dir2)
write.csv(dfall, paste0(path_out,"combined_pig_dat.csv"))
write.csv(pig_stat, paste0(path_out, "pig_summary_stat.csv"))
```

```{r log dat}
dir2 <- "//data//processed//"
path_out = paste0(root,dir2)
pig_dat <- read.csv(paste0(path_out,"combined_pig_dat.csv"))

add1 <- function(n) {
    n + 1
}

log_pig <- pig_dat %>% 
    mutate_at(.vars = vars(tot_chl_a:dp), add1) %>%
    mutate_at(.vars = vars(tot_chl_a:dp), .funs = (log = log10))

log_pig_stat <- log_pig %>%
    group_by(season) %>% 
    summarise_at(vars(tot_chl_a:dp),list(log_avg = mean, log_sd= sd, log_var= var), na.rm = TRUE)
write.csv(log_pig, paste0(path_out, "log_combined_pig_dat.csv"))
write.csv(log_pig, paste0(path_out, "log_pig_summary_stat.csv"))
```

```{r}
#  clustering by size fractionation
size_clust <- pig_dat %>%
    filter(sample != "WS20278-191") %>%
    #select(lon, lat, f_micro, f_nano, f_pico)
    select(hplc_gsfc_id, lon, lat, micro, nano, pico) %>%
    #select(hplc_gsfc_id, lon, lat, but_fuco, fuco, hex_fuco, perid) %>%
    drop_na()
rownames(size_clust) <- size_clust$hplc_gsfc_id 
 size_clust <-   select(size_clust,-hplc_gsfc_id)
size_clust <- scale(size_clust) # z-score

d1=dist(size_clust)
    
hc1 <-hclust(d1, method = "ward.D")
plot(hc1, cex=0.6, hang=-1)

opt_clust <- fviz_nbclust(size_clust, hcut, method = "silhouette", k.max = 24) + theme_minimal() + ggtitle("The Silhouette Plot")
clust_num_1 <- cutree(hc1, k=5)

factoextra::fviz_cluster(list(data=size_clust, cluster=clust_num_1))
s_clust_num_df <- data.frame(s_clust_num= clust_num)
size_clust <- data.frame(size_clust)
s_clus_groups <- merge(size_clust, s_clust_num_df, by="row.names")



```
