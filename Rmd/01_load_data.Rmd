---
title: "Merge Pigment Data"
author: "Sebastian DiGeronimo"
date: '2022-06-13'
output: html_document
---

# This file is to merge the separate HPLC data files into one

# List of TODOs 
* address notes from file to potentially ignore certain rows 
* start plotting
    * histogram, per stations, per pigments, etc
    * simple plots over time
    * maybe some heatmap
    * maybe map

# 1.0 ---- Load ----

## 1.1 Load Libraries
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
if (!nzchar(system.file(package = "librarian"))) 
    install.packages("librarian")

librarian::shelf(
    librarian, conflicted, ggplot2, tibble, tidyr, readr, purrr, dplyr, stringr,
    forcats, lubridate, glue, fs, magrittr, here,
    
    # additional
    rlang
)

conflicts_prefer(
    dplyr::filter(), 
    dplyr::select()
    )

source(here("scripts", "misc_functions.R"))
```

## 1.2 Create Directories
```{r create-dir}
# will create a set directory if does not exists
# useful for new projects
source(here("scripts", "create_dir.R")) 

create_dir(
  .loc = here(),
  cust_dir = 
   c(
     here("data", "raw", c("seascapes", "chemtax", "hplc", "microscopy"))
     ),
  showtree = TRUE,
  recurse  = 2)

rm(create_dir)
```

## 1.3 Get File Paths for HPLC Data

```{r file-paths}
# path location to find HPLC data
data_dir <- here("data", "raw", "hplc")

# pigment files
file_pig <-
  data_dir %>%
  dir_ls(
    recurse = FALSE,
    type    = "file",
    regexp  = "^[^~]*\\.xlsx$"
  ) %>%
  str_sort() %>%
  str_subset("ignore", negate = TRUE)
    

if (is_empty(file_pig)) {
    message(glue_col(
        "You may need to put raw HPLC data into a ", 
        "newly created directory for raw HPLC \ndata in:\n",
        "{red {data_dir}} (as of Jan 2023)"))
} else {
    file_pig
}
```

## 1.4 Load HPLC Data and Fix Issues

Files:
- M-K 06-12 report_may_and_sept_2016
- M-K 09-02 report_nov16_mar17_jun17_oct17_jan18
- M-K_05-17_report_mar16
- M-K 10-11 part1 report
- M-K 10-11 part2 report

Issues
- Tidy column names (janitor::make_clean_names)
- Rename columns
- Creates `date_time` column 
- Ignore -9999 (missing) and -8888 (Limit of Detection) 
- Corrects formatting issues

```{r load-data}
shelf(readxl, janitor, hms)

# ---- M-K 06-12 report_may_and_sept_2016 ----
# fix date and add datetime

df1 <-
  read_xlsx(
    file_pig[1],
    sheet = 2,
    skip  = 8,
    na    = c("-9999", "-8888"),
    .name_repair = make_clean_names
  ) %>%
  rename(
    lon = longitude,
    lat = latitude
  ) %>%
  mutate(
    gmt_time      = as_hms(gmt_time),
    date_time_utc = ymd_hms(
      str_c(
        year_of_sample,
        gregorian_month,
        day_of_gregorian_month,
        gmt_time,
        sep = " "
      ),
      tz = "utc"
    ),
    .before = lon
  )

# ---- M-K 09-02 report_nov16_mar17_jun17_oct17_jan18 ----
# fix date and add datetime
# convert indicate_if_filters_are_replicates to character
# fix gfc to gsfc

df2 <-
  read_xlsx(
    file_pig[2],
    sheet = 2,
    skip  = 8,
    na    = c("-9999", "-8888"),
    .name_repair = make_clean_names
  ) %>%
  mutate(
   time          = as_hms(time),
   date_time_utc = ymd_hms(
     str_c(
       year,
       month,
       day,
       time,
       sep = " "
     ),
     tz = "utc"
   ),
   .before = lon
 ) %>%
    
  # converted to character, b/c is logical
  mutate(
    indicate_if_filters_are_replicates =
      as.character(indicate_if_filters_are_replicates)
  ) %>%
    
  # fix gfc to gsfc
  rename(
    filter_storage_before_shipment_to_gsfc =
      filter_storage_before_shipment_to_gfc
  ) %>%
    
  # one station was included in metadata, but does not exist
  filter(!is.na(station))

# ---- M-K 10-11 part1 report ----
# fix date and add datetime
# fix water depth
# fix indicate_if_filters_are_replicates as character

df3 <-
  read_xlsx(
    file_pig[3],
    sheet = "Report",
    skip  = 8,
    na    = c("-9999", "-8888"),
    .name_repair = make_clean_names
  ) %>%
    
  # fix date and datetime
  mutate(
    time          = as_hms(time),
    date_time_utc = ymd_hms(
      str_c(
        year,
        month,
        day,
        time,
        sep = " "
      ),
      tz = "utc"
    ),
    .before = lon
  ) %>%
  mutate(
    indicate_if_filters_are_replicates =
      as.character(indicate_if_filters_are_replicates),

    # matches any digit or decimal and convert to numeric (issue with format)
    water_depth = str_extract(water_depth, "\\d*\\.{0,1}\\d"),
    water_depth = as.numeric(water_depth),
    water_depth = replace_na(water_depth, 0)
  )

# ---- M-K 10-11 part2 report ----
# fix misspelled month
# fix depth
# fix date and add datetime
 

df4 <-
  read_xlsx(
    file_pig[4],
    sheet = "Report",
    skip  = 8,
    na    = c("-9999", "-8888"),
    .name_repair = janitor::make_clean_names
  ) %>%
  
  # fixed misspelled month
  mutate(
    month = case_when(
      !month %in% c(month.name, month.abb) ~ str_extract(month, "\\w{3}"),
      .default = month
    ),
    depth = str_extract(depth, "\\d*\\.{0,1}\\d"),
    depth = as.numeric(depth)                   
  ) %>%
  # fix date and add datetime
  mutate(
    time          = as_hms(time),
    date_time_utc = ymd_hms(
      str_c(
        year,
        month,
        day,
        time,
        sep = " "
      ),
      tz = "utc"
    ),
    .before = lon
  )

# ---- M-K_05-17_report_mar16 ----
# fix date and add datetime
# date_extracted_month_day_year numeric to date, replace str to NA


df5 <-
  read_xlsx(
    file_pig[5],
    sheet = "Report",
    skip  = 8,
    na    = c("-9999", "-8888"),
    .name_repair = make_clean_names
  ) %>%
  rename(
    lon = longitude,
    lat = latitude
  ) %>%
  
  # fix date and add datetime
  mutate(
    gmt_time      = as_hms(gmt_time),
    date_time_utc = ymd_hms(
      str_c(
        year_of_sample,
        gregorian_month,
        day_of_gregorian_month,
        gmt_time,
        sep = " "
      ),
      tz = "utc"
    ),
    .before = lon
  ) %>%
    
  # converts numeric to date, replace str to NA
  mutate(
        temp = str_remove(date_extracted_month_day_year, "\\D+"),
        temp = as.numeric(temp),
        temp = janitor::excel_numeric_to_date(temp),
        temp = ymd(temp, tz = "utc"),
        date_extracted_month_day_year = temp
    )  %>%
  select(-temp) 

unshelf(readxl, janitor, hms)
```

# 2.0 ---- Merge Data Reports ----

## 2.1 Mapped Column Names

Over the year, column names coming from NASA had changed slightly. Here, the 
names that are equal are represented here to match to when add rows.

```{r colnames}
# select variables that match data sets
params <- c(
  # meta
  "hplc_gsfc_id" = "gsfc_lab_sample_code", "pi", "station",
  "sample" = "original_pi_sample_label", "cruise" = "cruise_name",
  "indicate_if_filters_are_replicates",
  "volfilt" = "volume_filtered_ml", "bottle" = "bottle_number",
  "depth" = "sampling_depth_meters",
  "water_depth" = "total_water_depth_meters",
  "name_of_water_body",

  # time
  "year" = "year_of_sample", "month" = "gregorian_month",
  "day" = "day_of_gregorian_month", "sdy" = "sequential_day_of_year",
  "time" = "gmt_time", "date_time_utc", "lon", "lat",

  # sample type
  "filter_type", "filter_diameter_mm",
  "filter_storage_before_shipment_to_gfsc" =
    "filter_storage_before_shipping_to_gsfc",

  # pigments
  "tot_chl_a", "tot_chl_b", "tot_chl_c", "alpha_beta_car", "but_fuco",
  "hex_fuco", "allo", "diadino", "diato", "fuco", "perid", "zea", "mv_chl_a",
  "dv_chl_a", "chlide_a", "mv_chl_b", "dv_chl_b", "chl_c1c2" = "chl_c12",
  "chl_c3", "lut", "neo", "viola", "phytin_a", "phide_a", "pras", "gyro",
  "tchl" = "t_chl", "ppc", "psc", "psp", "tcar" = "t_caro", "tacc" = "t_acc",
  "tpg" = "t_pg", "dp", "tacc_tchla" = "t_acc_tchla", "psc_tcar" = "psc_t_caro",
  "ppc_tcar" = "ppc_t_caro", "tchl_tcar" = "t_chl_t_caro", "ppc_tpg" = "ppc_tpig",
  "psp_tpg" = "psp_t_pg", "tchl_a_tpg" = "t_chl_a_t_pig",
  "comments", "sequential_sample_number"
)
```

## 2.2 Join Data

Stages of data merging are preformed by combing the most alike data first.

- df_merg = df3 and df2
- df_merg = df_merg and df4
- df_merg2 = df1 and df5
- df_all = df_merg and df_merg2

```{r merge-df}
shelf(paulponcet/statip)

# ---- merge df 2, 3, 4 ----

df_merg <- full_join(df3, df2)

df_merg <-
  mutate(
    df_merg,
    hplc_gsfc_id = case_when(
      is.na(hplc_gsfc_id) ~ gsfc_sample_code,
      .default = hplc_gsfc_id
    )
  )

df_merg <-
  full_join(df_merg, df4) %>%
  # one cell had "28A", converted to NA
  mutate(sequential_sample_number = as.numeric(sequential_sample_number))


# ---- merge df 1, 5 ----

df_merg2 <- full_join(df1, df5)


# ---- full merge ----

df_all <- 
  full_join(df_merg, df_merg2, by = params) %>%
  mutate(across(tot_chl_a:tchl_a_tpg, \(x) if_else(!is.na(x), x, 0)))
```

## 2.3 Add Seasonal Factor and Water Body Name

The data was grouped into 4 seasons using months.

Winter: 
    Dec, Jan, Feb
    
Spring:  
    Mar, Apr, May
    
Summer: 
    Jun, Jul, Aug
    
Autumn: 
    Sep, Nov, Oct

Water Body Names: 

- Florida Keys
- West Florida Shelf
- Southwest Florida Shelf

```{r szn-water-body-var}

# seasonal groups
szn <-
  list(
    "Winter" = month.abb[c(12, 1, 2)], # Dec, Jan, Feb
    "Spring" = month.abb[3:5],         # Mar, Apr, May
    "Summer" = month.abb[6:8],         # Jun, Jul, Aug
    "Autumn" = month.abb[9:11]         # Sep, Nov, Oct
  ) %T>% print()


# water body names
water_body <- list(
  "Florida Keys" = c(
    glue("{1:18}"),
    glue("9.{1:9}"), "9B", "24", "LK", "MR", "WS", "21.5"
  ),
  "Southwest Florida Shelf" = c(
    glue("{30:68}"),
    glue("57.{1:3}"), "KW1", "KW2", "KW4"
  ),
  "West Florida Shelf" = c(
    "Z04-068", "CBH", "NBH", "EB1",
    as.vector(outer(
      c("AMI", "V", "TB", "CW", "L", "GP", "RP", "ROME", "CAL", "BG"),
      c(1:12),
      str_c
    ))
  )
) %T>% print()

```

```{r add-season-water-body}
df_all <-
  df_all %>%
  mutate(
    # add season factor
    month  = month(date_time_utc, label = TRUE, abbr = TRUE),
    season = case_match(
      month,
      szn[[1]] ~ names(szn)[1],        # Winter
      szn[[2]] ~ names(szn)[2],        # Spring
      szn[[3]] ~ names(szn)[3],        # Summer
      szn[[4]] ~ names(szn)[4],        # Autumn
      .default = NA_character_
    ),
    season = fct(season, levels = names(szn)),
    
    # fix case of stations
    station = str_replace_all(station, "\\s", ""),
    station = str_to_upper(station),
    
    # correct water body name
    name_of_water_body = case_match(
     station,
     water_body[[1]] ~ names(water_body)[1],
     water_body[[2]] ~ names(water_body)[2],
     water_body[[3]] ~ names(water_body)[3],
     .default = NA_character_
     ),
    .after = month
  ) %T>% print()
```


## 2.4 Fix Lat/Lon

Then, the lat and lon columns were adjusted
- lon < 0 (-84 to -79)
- lat > 0 (24 - 27)
- TB1 hard coded
  - 27.8013 lat
  - -82.8819 lon
 
A second check to make sure the lat/lon for every station matched over time and
would select the most frequently occuring as the correct one. 

```{r fix-df}
df_all <-
  df_all %>%
  
  # fix small errors with negative values
  mutate(
    lat = case_when(
      lat < 0 ~ lat * (-1),
      .default = lat
    ),
    lon = case_when(
      lon > 0 ~ lon * (-1),
      .default = lon
    )
  ) %>%
    
  # fix spacing of stations
  mutate(

    # specifically TB1 was off, need to use NOAA AOML for coords
    lat = case_when(
      station == "TB1" ~ 27.8013,
      .default = lat
    ),
    lon = case_when(
      station == "TB1" ~ -82.8819,
      .default = lon
    )
  )


# summarize most freq value for lat/lon per station
dat_loc <- 
  df_all %>% 
  select(station, lat, lon) %>%
  summarise(
      .by = station,
      lat_mod = statip::mfv1(lat),
      lon_mod = statip::mfv1(lon),
  ) 

# left join dat_loc to df_all
df_all <-
  df_all %>%
  left_join(dat_loc, by = "station") %>%
  mutate(
    lat = lat_mod,
    lon = lon_mod,
    depth = if_else(is.na(depth), 1, depth),
  ) %>%
  select(-lat_mod, -lon_mod)

unshelf(paulponcet/statip)

```

## 2.5 Map Points of Data

Manual checking that each distinct station with lat/lon roughly matched their 
expected locations.

```{r plot-points}
map_plt <-
  ggplot() +
  geom_point(
    data = df_all,
    aes(
      x = lon,
      y = lat,
      color = name_of_water_body
    ),
    show.legend = FALSE
  ) +
  geom_point(
    data = dat_loc,
    aes(
      x = lon_mod,
      y = lat_mod,
      group = station
    ),
    color = "purple",
    shape = 21,
    alpha = 25,
    size  = 3,
    inherit.aes = FALSE,
    show.legend = FALSE
  ) +
    
  # add station names
  ggrepel::geom_text_repel(
    data = distinct(df_all, station, lat, lon),
    aes(
      x = lon,
      y = lat,
      label = station
    ),
    min.segment.length = 0,
    max.overlaps = 50,
    size = 2
  ) +
  labs(
    x = NULL,
    y = NULL
   ) +
  theme_bw()


map_plt

if (interactive() & nzchar(system.file(package = "plotly"))) {
  # will need plotly
  plotly::ggplotly(map_plt)
}
```

## 2.6 Clean Workspace
```{r clean-workspace}
if (menu(c("Remove Variables", "Keep Variables"), 
         title = "Do you want to remove variables?") == 1 ) {
 rm(df1, df2, df3, df4, df5, df_merg, df_merg2, 
    params, map_plt, szn, water_body, dat_loc)
}
```


# 3.0 Calculate Summary Statistics

Calculate for each season and water body:
- Average,
- Standard deviations 
- Variance

```{r summary-statistics}
pig_stat <-
  df_all %>%
  summarise(
    .by = c(season, name_of_water_body),
    across(
      tot_chl_a:tchl_a_tpg,
      list(
        avg = ~ mean(.x, na.rm = TRUE),
        sd  = ~ sd(.x, na.rm = TRUE),
        var = ~ var(.x, na.rm = TRUE)
      )
    )
  ) %T>% print()
```

# 3.0 ---- Calculate Community Composition from Diagnostic Biomarkers ----

Based on Uitz, 2006. 

The coefficients were used in our calculation of diagnostic biomarker based size
classes

$$
\begin{align}
& \text{Diagnostic Pigment} \\
& dp = \\
& (1.41 \times \text{fuco} + 
   1.41 \times \text{perid})\space+ \\
& (1.27 \times \text{hex fuco} +
   0.35 \times \text{but fuco} +  
   0.6 \times \text{allo})\space+ \\
& (1.01 \times \text{total chl-b} +
   0.86 \times \text{zea}); \\
  
\\

& \text{Fraction (% biomass)}: \\

& frac~_{\text{micro}} = 
     1.41 \times \text{fuco} + 
     1.41 \times \text{perid}; \\
            
& frac~_{\text{nano}} = 
    1.27 \times \text{hex fuco} +
    0.35 \times \text{but fuco} + 
    0.6 \times \text{allo}; \\
                
& frac~_{\text{pico}} = 
    1.01 \times \text{total chl-b} +
    0.86 \times \text{zea} \\

\\
    
& \text{Biomass}~(mg~L^{-1}): \\

& B_{\text{micro}} =
    frac~_{\text{micro}} \times \text{Chlor-a} \\
    
& B_{\text{nano}} = 
    frac~_{\text{nano}} \times \text{Chlor-a} \\

& B_{\text{pico}} =
    frac~_{\text{pico}} \times \text{Chlor-a} \\

 \end{align} 
$$
```{r diagnostic-biomarker-size-class}
df_all <-
  df_all %>%
  mutate(
    # diagnostic pigment
    dp_w =
      1.41 * fuco + 1.41 * perid + 1.27 * hex_fuco + 0.35 * but_fuco +
        0.6 * allo + 1.01 * tot_chl_b + 0.86 * zea,

    # fractions
    f_micro = (1.41 * fuco + 1.41 * perid) / dp_w,
    f_nano  = (1.27 * hex_fuco + 0.35 * but_fuco + 0.6 * allo) / dp_w,
    f_pico  = (1.01 * tot_chl_b + 0.86 * zea) / dp_w,

    # biomass
    micro = f_micro * tot_chl_a,
    nano  = f_nano * tot_chl_a,
    pico  = f_pico * tot_chl_a
  )
```


# 4.0 ---- Filter for FL Keys Data ----

The data filtered for FL Keys is used in the CHEMTAX program. The cluster code 
is added for the cluster code column in the CHEMTAX spreadsheet.

Cluster Code:
1 = Winter
2 = Spring
3 = Summer
4 = Autunm

The columns selected are the columns actually used in the CHEMTAX program and
all other columns are removed. The results can be merged back in using the 
`hplc_gsfc_id`.

```{r fl-keys-only}
# filter for Florida Keys and cluster by seasons
fl_keys_chemtax_seasons <-
  df_all %>%
  filter(name_of_water_body == "Florida Keys") %>%
  mutate(cluster_code = as.numeric(season)) %>%
  
  # necessary columns 
  select(
    hplc_gsfc_id,
    cluster_code,
    sample,
    chl_c3,
    chl_c1c2,
    perid,
    but_fuco,
    fuco,
    pras,
    hex_fuco,
    zea,
    allo,
    lut,
    tot_chl_b,
    dv_chl_a,
    tot_chl_a
  )
```


# 5.0 ---- Convert pigments to log ----

Convert all pigment values to logarithm.

Calculate:
- Log base 10
- Average
- Standard deviation
- Variance

```{r log-dat}
# transform pigments to log10 and add small value
val <- 0.001 # change to 1 or 0.001

log_pig <- mutate(df_all, across(tot_chl_a:dp, ~ log10(.x + val)))

# summarise
log_pig_stat <-
  log_pig %>%
  pivot_longer(
    tot_chl_a:dp,
    names_to  = "pigment",
    values_to = "log_conc"
  ) %>%
  filter(!is.na(log_conc)) %>%
  summarise(
    .by = c(season, name_of_water_body, pigment),
    log_avg = mean(log_conc),
    log_sd  = sd(log_conc),
    log_var = var(log_conc)
  ) %>%
  mutate(
    .keep = "none",
    name_of_water_body,
    season,
    pigment,
    avg = 10^log_avg - val,
    sd  = 10^log_sd - val,
    var = 10^log_var - val,
    log_avg,
    log_sd,
    log_var
  )

log_pig_stat %>%
  pivot_wider(
    data         = .,
    id_cols      = c(name_of_water_body, season),
    names_from   = pigment,
    values_from  = c(log_avg:last_col()),
    names_glue   = "{pigment}_{.value}",
    names_repair = janitor::make_clean_names
  )

rm(val)
```



# ---- 6.0 Save data ----

1A. Combined pigment data - selected columns
1B. Combined pigment data - all columns
2. Average, standard deviation and variance of combined pigment
3. Log transformed combine pigment data
4. Average, standard deviation and variance of log combined pigment
5. Florida Keys filtered data with necessary columns to be used in CHEMTAX 

```{r save-combined-data}
# location to save data
path_out <- here("data", "processed", "load_data")

# overwrite or not
# ovrwrt_sv <- TRUE
ovrwrt_sv <- FALSE

# 1A. combined date
df_all %>%
  # bad sample, contaminated with blue ink
  filter(!str_detect(sample, "WS18120_103"))  %>%
  select(
      -c(pi, volfilt, filter_type:filter_storage_before_shipment_to_gfsc, 
         comments:other, 
         collected_with_positive_pressure_or_vaccuum:vx_ml)
  )  %>%
  relocate(water_type, .after = name_of_water_body) %>%
  save_csv(
    .data          = .,        
    save_location  = path_out,
    save_name      = "combined_pig_dat",
    overwrite      = ovrwrt_sv,
    verbose        = TRUE,
    time_stamp_fmt = NULL
  )

# 1B. combined date
save_csv(
  .data          = df_all,        
  save_location  = path_out,
  save_name      = "combined_pig_dat_all",
  overwrite      = ovrwrt_sv,
  verbose        = TRUE,
  time_stamp_fmt = NULL
)

# 2. stats on combined date
save_csv(
  .data          = pig_stat,        
  save_location  = path_out,
  save_name      = "pig_summary_stat",
  overwrite      = ovrwrt_sv,
  verbose        = TRUE,
  time_stamp_fmt = NULL
)

# 3. log trans of pigment
save_csv(
  .data          = log_pig,        
  save_location  = path_out,
  save_name      = "log_combined_pig_dat",
  overwrite      = ovrwrt_sv,
  verbose        = TRUE,
  time_stamp_fmt = NULL
)

# 4. log trans mean, std dev, var
save_csv(
  .data          = log_pig_stat,        
  save_location  = path_out,
  save_name      = "log_pig_summary_stat",
  overwrite      = ovrwrt_sv,
  verbose        = TRUE,
  time_stamp_fmt = NULL
)

# 5. FL Keys chemtax season clusters
save_csv(
  .data          = fl_keys_chemtax_seasons,        
  save_location  = path_out,
  save_name      = "chemtax_season_clust",
  overwrite      = ovrwrt_sv,
  verbose        = TRUE,
  time_stamp_fmt = NULL
)

rm(ovrwrt_sv)
```