---
title: "Merge Pigment Data"
author: "Sebastian DiGeronimo"
date: '2022-06-13'
output: html_document
---

# This file is to merge the separate HPLC data files into one

# List of TODOs 
* address notes from file to potentially ignore certain rows 
* start plotting
    * histogram, per stations, per pigments, etc
    * simple plots over time
    * maybe some heatmap
    * maybe map

```{r setup, include=FALSE}
# root <- rprojroot::find_rstudio_root_file()
knitr::opts_chunk$set(echo = TRUE)
library("ggplot2")
library("tibble")
library("tidyr")
library("readr")
library("purrr")
library("dplyr")
library("stringr")
library("forcats")
library("lubridate")
library("glue")
library("fs")
library("magrittr")
library("here")
# library("broom") # optional

```

```{r create-dir}
# will create a set directory if does not exists
# useful for new projects
subDir <-
    c("data/raw",
      "data/processed",
      "data/plots",
      "data/metadata",
      "data/raw/seascapes",
      "data/raw/chemtax",
      "data/raw/microscopy",
      "Rmd",
      "scripts")

fs::dir_create(path = here(subDir))
rm(subDir)
```


```{r file-paths}
# find pigment data
dir      <- here("data", "raw")
path_out <- here("data", "processed")

# pigment files
file.pig <-
  fs::dir_ls(path = dir,
             recurse = TRUE,
             # included ^[^~]* to not match ~, means that a file is opened
             regexp = "^[^~]*\\.xlsx$") %>% 
    str_sort()
```

# HPLC data is loaded and cleanup
Cleans name for tidying, renames some, creates date_time column, replace -9999 to
NA, -8888 to 0 (is LOD), corrects formatting issues,
```{r load-data}
# ---- M-K 06-12 report_may_and_sept_2016 ----

df <-
    readxl::read_xlsx(
        file.pig[1],
        sheet = 2,
        skip = 8,
        na = "-9999",
        .name_repair = janitor::make_clean_names
    ) %>%

    rename(lon = longitude,
           lat = latitude) %>%
    
    mutate(
        gmt_time = hms::as_hms(strftime(gmt_time, format = "%H:%M:%S", 
                                        tz = "utc")),
        date_time_utc = ymd_hms(
            paste(
                year_of_sample,
                gregorian_month,
                day_of_gregorian_month,
                gmt_time
            ),
            tz = "utc"
        ),
        .before = lon

    ) %>%
    
    # set -8888 to 0, represent below Limit of Detection (LOD)
    replace(., . == -8888, 0)

# ---- M-K 09-02 report_nov16_mar17_jun17_oct17_jan18 ----
df2 <-
    readxl::read_xlsx(
        file.pig[2],
        sheet = 2,
        skip = 8,
        na = "-9999",
        .name_repair = janitor::make_clean_names
    ) %>%
    
    mutate(
        time = hms::as_hms(strftime(time, format = "%H:%M:%S",
                                     tz = "utc")),
        date_time_utc = ymd_hms(paste(year, month, day, time),
                                tz = "utc"),
        .before = lon
    ) %>%
    
    #converted to character, b/c is logical
    mutate(indicate_if_filters_are_replicates = as.character(indicate_if_filters_are_replicates)) %>%
    
    rename(filter_storage_before_shipment_to_gsfc = filter_storage_before_shipment_to_gfc) %>%
    
    # one station was included in metadata, but does not exist
    filter(!is.na(station)) %>%
    
    # set -8888 to 0, represent below Limit of Detection (LOD)
    replace(., . == -8888, 0)

# ---- M-K 10-11 part1 report ----

df3 <-
    readxl::read_xlsx(
        file.pig[3],
        sheet = "Report",
        skip = 8,
        na = "-9999",
        .name_repair = janitor::make_clean_names
    ) %>%

    

    mutate(
        time = hms::as_hms(strftime(time, format = "%H:%M:%S",
                                     tz = "utc")),
        date_time_utc = ymd_hms(paste(year, month, day, time),
                                tz = "utc"),
        .before = lon
    ) %>%

    
    mutate(
        indicate_if_filters_are_replicates = as.character(indicate_if_filters_are_replicates),
        # matches any digit or decimal and convert to numeric (issue with format)
        water_depth = as.numeric(str_extract(water_depth, "\\d*\\.{0,1}\\d")),
        water_depth = replace_na(water_depth, 0)
    ) %>%
    
    # set -8888 to 0, represent below Limit of Detection (LOD)
    replace(., . == -8888, 0)

# ---- M-K 10-11 part2 report ----
df4 <-
    readxl::read_xlsx(
        file.pig[4],
        sheet = "Report",
        skip = 8,
        na = "-9999",
        .name_repair = janitor::make_clean_names
    )  %>%
    
    # Fixed misspelled month
    mutate(month = case_when(
        !month %in% c(month.name, month.abb) ~ str_extract(month, "\\w{3}"),
        TRUE ~ month
    )) %>%
    

    mutate(
        time = hms::as_hms(strftime(time, format = "%H:%M:%S",
                                     tz = "utc")),
        date_time_utc = ymd_hms(paste(year, month, day, time),
                                tz = "utc"),
        .before = lon
    ) %>%
    
    mutate(depth = as.numeric(str_extract(depth, "\\d*\\.{0,1}\\d"))) %>%
    
    # set -8888 to 0, represent below Limit of Detection (LOD)
    replace(., . == -8888, 0)

# ---- M-K_05-17_report_mar16 ----
df5 <-
    readxl::read_xlsx(
        file.pig[5],
        sheet = "Report",
        skip = 8,
        na = "-9999",
        .name_repair = janitor::make_clean_names
    ) %>%
    
    rename(lon = longitude,
           lat = latitude) %>%
    
    mutate(
        gmt_time = hms::as_hms(strftime(gmt_time, format = "%H:%M:%S",
                                         tz = "utc")),
        date_time_utc = ymd_hms(
            paste(
                year_of_sample,
                gregorian_month,
                day_of_gregorian_month,
                gmt_time
            ),
            tz = "utc"
        ),
        .before = lon
    ) %>%
    
    # converts numeric to date, replace str to NA
    mutate(
        date_extracted_month_day_year = case_when(!is.na(
            as.numeric(date_extracted_month_day_year)
        ) ~ paste(
            as.Date(as.numeric(date_extracted_month_day_year), origin = "1899-12-30")
        ),
        TRUE ~ NA_character_),
        date_extracted_month_day_year = ymd(date_extracted_month_day_year, tz = "utc")
    ) %>%
    
    # set -8888 to 0, represent below Limit of Detection (LOD)
    replace(., . == -8888, 0)

```

# Merge data
```{r merge-df}
# ---- merge df 2, 3, 4 ----
df_merg  <-
    full_join(df3, df2)

df_merg  <-
    mutate(df_merg,
           hplc_gsfc_id = case_when(is.na(hplc_gsfc_id) ~ gsfc_sample_code,
                                    TRUE ~ hplc_gsfc_id))

df_merg  <- full_join(df_merg, df4) %>%
    
    # one cell had "28A", converted to NA
    mutate(sequential_sample_number = as.numeric(sequential_sample_number)) 

# ---- merge df 1, 5 ----
df_merg2 <- full_join(df, df5)

# ---- full merge ----
# select variables that match data sets
params <- c("hplc_gsfc_id"="gsfc_lab_sample_code", "pi", "station", "sample" = "original_pi_sample_label", 
            "cruise"="cruise_name", "indicate_if_filters_are_replicates",
            "volfilt" = "volume_filtered_ml", "bottle" ="bottle_number", 
            "depth" = "sampling_depth_meters", "water_depth" = "total_water_depth_meters",
            "name_of_water_body", "year" = "year_of_sample", "month"= "gregorian_month",
            "day" = "day_of_gregorian_month", "sdy" = "sequential_day_of_year", 
            "time"="gmt_time", "date_time_utc","lon", "lat", "filter_type",
            "filter_diameter_mm", "filter_storage_before_shipment_to_gfsc"="filter_storage_before_shipping_to_gsfc",
            "tot_chl_a", "tot_chl_b", "tot_chl_c", "alpha_beta_car","but_fuco", 
            "hex_fuco", "allo", "diadino", "diato", "fuco", "perid", "zea", "mv_chl_a", 
            "dv_chl_a", "chlide_a", "mv_chl_b", "dv_chl_b", "chl_c1c2" = "chl_c12",
            "chl_c3", "lut", "neo", "viola", "phytin_a", "phide_a", "pras", "gyro", 
            "tchl"="t_chl", "ppc", "psc", "psp", "tcar"="t_caro", "tacc" = "t_acc",
            "tpg" = "t_pg", "dp", "tacc_tchla" = "t_acc_tchla", "psc_tcar" = "psc_t_caro",
            "ppc_tcar" = "ppc_t_caro", "tchl_tcar"="t_chl_t_caro", "ppc_tpg" = "ppc_tpig",
            "psp_tpg" = "psp_t_pg", "tchl_a_tpg" = "t_chl_a_t_pig",
            "comments", "sequential_sample_number")


df_all <- full_join(df_merg, df_merg2, by = params)  %>%
    
    # fix small errors with negative values
    mutate(lat = case_when(lat < 0 ~ lat * (-1),
                           TRUE ~ lat),
           lon = case_when(lon > 0 ~ lon * (-1),
                           TRUE ~ lon)) %>%
    
    # fix spelling and spacing of stations
    mutate(
        station = stringr::str_replace_all(station, fixed(" "), ""),
        station = stringr::str_to_upper(station),
        
        # specifically TB1 was off, need to use NOAA AOML for coords
        lat = case_when(station == "TB1" ~ 27.8013, TRUE~lat),
        lon = case_when(station == "TB1" ~ -82.8819, TRUE~lon)
    ) 

# ---- fix lat long ----
# summarize most freq value for lat/lon per station
indx <- df_all %>% 
    select(station, lat, lon) %>%
    group_by(station) %>%
    # summarise(n = n())
    summarise(
        # lat_mod = modeest::mlv(lat, method = "mfv"),
        # lon_mod = modeest::mlv(lon, method = "mfv1"),
        lat_mod = statip::mfv1(lat),
        lon_mod = statip::mfv1(lon),
        # sumss = sum(lat)
        # .groups = "drop_last"
    ) 

# left join indx to df_all
df_all <- df_all %>%
    # group_by(station) %>%
    left_join(indx, by = "station") %>%
    mutate(lat = lat_mod, 
           lon = lon_mod) %>%
    select(-lat_mod, -lon_mod)

rm(df, df2, df3, df4, df5, df_merg, df_merg2, params)
```


```{r plot-points}
# will need plotly 
# plotly::ggplotly(
    # ggplot() +
    #     geom_point(data= df_all, aes(x = lon, y = lat, color = station), show.legend = F) +
        # geom_point(data = indx, mapping = aes(lon_mod, lat_mod, stn = station), shape = 21, fill = NA ,
        #            inherit.aes = F, show.legend = F) #+
#         # geom_point(data=tibble(x = -82.8819, y =	27.8013), aes(x=x, y=y), color = "black")
# )

# for looking at similarities in the column names between different files
# x <- cbind(names(df),names(df2),names(df3),names(df4),names(df5))
# x2 <- cbind(names(df234), names(df15))
```

```{r summary-statistics}
# group by seasons
winter <- c("Dec", "Jan", "Feb")
spring <- c("Mar", "Apr", "May")
summer <- c("Jun", "Jul", "Aug")
autumn <- c("Sep", "Nov", "Oct")

df_all <- df_all %>% 
    mutate(
    month  = strtrim(month, 3),
    season = case_when(
        month %in% winter ~ "Winter",
        month %in% spring ~ "Spring",
        month %in% summer ~ "Summer",
        month %in% autumn ~ "Autumn",
    ),
    .after = month
)

# average and standard deviations for each pigment
pig_stat <- df_all %>%
    group_by(season) %>%
    summarise_at(vars(tot_chl_a:tchl_a_tpg),
                 list(avg = mean, sd = sd, var = var),
                 na.rm = TRUE)

```

# Calculate size fractionation based on Uitz, 2006
```{r size-fractionation}
df_all <- df_all %>%
    mutate(
        # diagnostic pigment
        dp_w =
            1.41 * fuco + 1.41 * perid + 1.27 * hex_fuco + 0.35 * but_fuco +
            0.6 * allo + 1.01 * tot_chl_b + 0.86 * zea,
        
        # fractions
        f_micro = (1.41 * fuco + 1.41 * perid) / dp_w,
        f_nano  = (1.27 * hex_fuco + 0.35 * but_fuco + 0.6 * allo) / dp_w,
        f_pico  = (1.01 * tot_chl_b + 0.86 * zea) / dp_w,
        
        # biomass
        micro   = f_micro * tot_chl_a,
        nano    = f_nano * tot_chl_a,
        pico    = f_pico * tot_chl_a
    )
```

# Save pigment data combined and mean/std dev
```{r save-combined-data}
if (FALSE) {
    readr::write_csv(df_all, here(path_out, "combined_pig_dat.csv"))
    readr::write_csv(pig_stat, here(path_out, "pig_summary_stat.csv"))
    }
```
# Convert pigments to log
```{r log-dat}
# read combined pigment data 
if (!exists("df_all")) {
    pig_dat  <- read_csv(here(path_out,"combined_pig_dat.csv"))
} else {
    pig_dat <- df_all
}

# transform pigments to log10 
val     <- 0.001 # change to 1 or 0.001

log_pig <- 
    pig_dat %>%
    mutate(
           across(tot_chl_a:dp,
                  ~ log10(.x + val)))


# TODO: maybe I don't need to do this
    # log_pig %>% 
    #     select(season, tot_chl_a:dp) %>%
    #     group_by(season) %>%
    #     summarise(across(tot_chl_a:dp, .fn = list(mean = mean, sd = sd, var = var), na.rm = TRUE,
    #            .names = "{.col}_{.fn}")) %>%
    #             pivot_longer(2:last_col(), 
    #              names_to  = "pigment", 
    #              values_to = "log_conc")
    
log_pig_stat <-
    log_pig %>%
    pivot_longer(tot_chl_a:dp, 
                 names_to  = "pigment", 
                 values_to = "log_conc") %>% 
    
    filter(!is.na(log_conc)) %>% 
    
    group_by(season, pigment) %>% 
    
    summarise(
        log_avg = mean(log_conc),
        log_sd  = sd(log_conc),
        log_var = var(log_conc)
    ) %>%
    
    transmute(pigment,
              avg     = 10^log_avg - val,
              sd      = 10^log_sd - val,
              var     = 10^log_var - val,
              log_avg,
              log_sd,
              log_var)
```

# Filter for FL Keys specifically
```{r fl-keys-only}
# filter for Florida Keys and cluster by seasons
chemtax_seasons <- 
    pig_dat %>%
    filter(name_of_water_body == "Florida Keys") %>%
    mutate(cluster_code = case_when(season == "Winter" ~ 1,
                                    season == "Spring" ~ 2, 
                                    season == "Summer" ~ 3,
                                    season == "Autumn" ~ 4)
           ) %>%
    dplyr::select(hplc_gsfc_id, 
                  cluster_code, 
                  sample, 
                  chl_c3, 
                  chl_c1c2, 
                  perid, 
                  but_fuco,
                  fuco, 
                  pras, 
                  hex_fuco, 
                  zea, 
                  allo, 
                  lut, 
                  tot_chl_b, 
                  dv_chl_a, 
                  tot_chl_a)
```


# Save data
```{r save-data}
if (FALSE) {
    # log trans of pigment
    write_csv(log_pig, 
              here(path_out, "log_combined_pig_dat.csv"))
    
    # mean, std dev, var
    write_csv(log_pig_stat, 
              here(path_out, "log_pig_summary_stat.csv"))
    
    # chemtax season clusters
    write_csv(chemtax_seasons, 
              here(path_out,"chemtax_season_clust.csv"))
    }
```

